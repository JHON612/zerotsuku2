{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34c960a3-9dc3-4583-85f3-433707550778",
   "metadata": {},
   "source": [
    "# 6.2 勾配消失とLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e150ebe-453b-4efe-9efe-a78c0282f0b9",
   "metadata": {},
   "source": [
    "- RNNには勾配消失という問題点あり<br>\n",
    "↓<br>\n",
    "- ゲート付きRNN\n",
    "    - 代表的なモデル\n",
    "        - LSTM ⇦この節で取り上げ\n",
    "        - GTU etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dbc113-8817-4c76-854a-69f395d79e42",
   "metadata": {},
   "source": [
    "## 6.2.1 LSTMのインターフェース"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b5c307-5bc2-470e-bd57-3fb903227570",
   "metadata": {},
   "source": [
    "- RNN記法を下図のように簡略化\n",
    "- $ tanh(h_{t-1}W_h + x_tW_x + b) $ という計算を「tanh」と表す"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e78647e-1683-494a-b209-8661cda931cf",
   "metadata": {},
   "source": [
    "![fig6](fig6/6_10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dd4c2b-ee4b-4ae9-a3fe-d85ed57dd334",
   "metadata": {},
   "source": [
    "- RNNレイヤとLSTMレイヤの比較(下図)\n",
    "    - LSTMにはc(記憶セル)あり\n",
    "        - 記憶セルの特徴\n",
    "            - 自分自身だけで(LSTMレイヤ内だけで)データの受け渡し・他レイヤへの出力はしない"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c72e7e-78bb-4b6d-9f73-34f45c466063",
   "metadata": {},
   "source": [
    "![fig6](fig6/6_11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b55e8f-0ed6-4251-93c1-1b1c47281d4e",
   "metadata": {},
   "source": [
    "## 6.2.2 LSTMレイヤの組み立て"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53d7620-56a6-4260-abf1-b4b50ffd2045",
   "metadata": {},
   "source": [
    "- 現在の記憶セル$c_t$は($c_{t-1}, h_{t-1}, x_t$)からの計算によって算出\n",
    "- ポイント\n",
    "    - 更新された$c_t$を使って、隠れ状態の$h_t$が計算される\n",
    "        - $h_t = tanh(c_t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023e9d4d-246c-43a4-9ab1-4ef86ef17aea",
   "metadata": {},
   "source": [
    "![fig6](fig6/6_12.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643d2660-2a6f-4fe6-ad9e-a57936b195ed",
   "metadata": {},
   "source": [
    "- LSTMにおける「ゲート」の機能\n",
    "    - どれだけゲートを開くか、水を次へ流すかをコントロール\n",
    "        - 開き具合は、0.0~1.0 までの実数で表される\n",
    "        - ゲートの開き具合のコントロールの為に、専用の重みパラメータが用いられる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8517b8a6-9daa-4f15-97fe-d1b8220dc1db",
   "metadata": {},
   "source": [
    "![6_14](fig6/6_14.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a356875-2d39-4d51-9f39-55e29dd1d745",
   "metadata": {},
   "source": [
    "## 6.2.3 outputゲート"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0557a226-c438-485d-85a3-252e8b745441",
   "metadata": {},
   "source": [
    "- outputゲート\n",
    "    - $tanh(c_t)$ の各要素に対して「それらが次時刻の隠れ状態($h_t$)としてどれだけ重要か」を調整\n",
    "    - 開き具合(次へ何%だけ通すか)は、入力$x_t$と前の状態$h_{t-1}$から求める\n",
    "    - ここで使用する重みパラメータやバイアスの上付き文字に$o$(outputの頭文字)を使用\n",
    "    - sigmoind関数はα()で表す\n",
    "    ![6_1](fig6/6_1.png)\n",
    "    - $o$ と $tanh(c_t)$の要素ごとの積を$h_t$として出力\n",
    "    ![6_15](fig6/6_15.png)\n",
    "    - outputゲートで行う式の計算を「α」で表す\n",
    "    - $h_t$は$o$と$tanh(c_t)$の積によって計算\n",
    "        - アダマール積\n",
    "        ![6_2](fig6/6_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30781a82-39ec-4979-a220-1179dad3c40d",
   "metadata": {},
   "source": [
    "## 6.2.4 forgetゲート"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f6a56d-363b-4cc7-a5ab-ee3e0caba7f1",
   "metadata": {},
   "source": [
    "- 記憶セル($c$)に対して「何を忘れるか」を明示的に指示\n",
    "- ![6_16](fig6/6_16.png)\n",
    "- ![6_3](fig6/6_3.png)\n",
    "    - 式(6.3)によってforgetゲートの出力fが求められる\n",
    "    - このfと前の記憶セルである$c_{t-1}$との要素ごとの積($c_t = f⊙c_{t-1}$)によって$c_{t}$が求められる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc8bd65-94c8-428c-9fda-5c71cfcb9e36",
   "metadata": {},
   "source": [
    "## 6.2.5 新しい記憶セル"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05003208-4589-45c2-a3c6-ff432f51be4a",
   "metadata": {},
   "source": [
    "- 新しく覚えるべき情報を記憶セルに追加する必要あり(現状は忘れる機能のみ)\n",
    "- 下図のようにtanhノードを新たに追加\n",
    "![6_17](fig6/6_17.png)\n",
    "- tanhノードによって計算された結果が前時刻の記憶セル$c_{t-1}$に加算される\n",
    "- このノードは「ゲート」ではなく新しい「情報」を記憶セルに追加することが目的\n",
    "![6_4](fig6/6_4.png)\n",
    "- このgが前時刻の$c_{t-1}$に加算されることで新しい記憶が生まれる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36c1743-ea4a-47d2-ac47-de65f547f15f",
   "metadata": {},
   "source": [
    "## 6.2.6 inputゲート"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc91219-0e73-49dd-93c4-ac39139d13e7",
   "metadata": {},
   "source": [
    "- gに対してゲートを加える\n",
    "![6_18](fig6/6_18.png)\n",
    "- gの各要素が新たに追加する情報としてどれだけ価値があるかを判断\n",
    "- inputゲートによって重みづけされた情報が新たに追加される\n",
    "- inputゲートを「α」で表し、その出力をiとする\n",
    "![6_5](fig6/6_5.png)\n",
    "- iとgの要素ごとの積の結果を記憶せるに追加"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955f34de-f81a-46a8-bb3f-26b27a7a620e",
   "metadata": {},
   "source": [
    "## 6.2.7 LSTMの勾配の流れ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e8735e-0510-4c75-9e43-241686407556",
   "metadata": {},
   "source": [
    "- LSTMが勾配消失を起こさない理由\n",
    "    - →記憶セルcの逆伝播に注目すると見えてくる\n",
    "\n",
    "![6_19](fig6/6_19.png)\n",
    "\n",
    "- 記憶セルにフォーカス\n",
    "    - 「+」ノード・・・上流から伝わる勾配をそのまま流すだけ→勾配の変化(劣化)は無し\n",
    "    - 「×」ノード・・・「要素ごとの積(アダマール積)」\n",
    "        - RNNの逆伝播では行列の積を繰り返し行ってきたので勾配消失・爆発が発生\n",
    "        - LSTMの逆伝播では、毎時刻異なるゲート値によって要素ごとの積を計算<br>→勾配消失を起こさない理由\n",
    "        - 「×」ノードの計算はforgetゲートによってコントロール\n",
    "            - 「忘れるべき」と導いた勾配の要素は小さく\n",
    "            - 「忘れてはいけない」と導いた勾配の要素は劣化することなく過去方向へ伝わる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc018cb3-ccef-4540-b32f-83ad520c5048",
   "metadata": {},
   "source": [
    "# 6.3 LSTMの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79be8a9d-d20b-43c0-8d72-9d597f3858a5",
   "metadata": {},
   "source": [
    "- 最初に、1ステップの処理をLSTMクラスとして実装\n",
    "- そして、Tステップ分をまとめて処理するクラスをTimeLSTMとして実装\n",
    "-　LSTMで行う計算は下図 <br>\n",
    "![6_6](fig6/6_6.png)<br>\n",
    "- 式(6.6)の4つのアフィン変換※がポイント(※ $xW_x + hW_h + b$のような式)\n",
    "        - 一つの式にまとめて計算可能\n",
    "![6_20](fig6/6_20.png)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef51bdea-a504-4f37-9f6e-eba4e0420995",
   "metadata": {},
   "source": [
    "- 本来であれば4回個別に行っていたアフィン変換の計算を1回の計算で済ませることが可能に<br>→計算の高速化\n",
    "- $W_x, W_h, b$　にそれぞれ4つ分の重みが含まれていると仮定して、LSTMの計算グラフを図示<br>\n",
    "![6_21](fig6/6_21.png)\n",
    "- ここでは初めに4つ分のアフィン変換をまとめて実施\n",
    "-　そして、sliceノードによって、その4つの結果を取り出す\n",
    "    - sliceノード・・・アフィン変換の結果を4分割して取り出すだけの単純なノード"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1007c86d-5bea-4a7c-aaa8-bbbadfeff132",
   "metadata": {},
   "source": [
    "◆LSTMクラスの初期化コード\n",
    "```python\n",
    "class LSTM:\n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        '''\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        Wx: 入力`x`用の重みパラーメタ（4つ分の重みをまとめる）\n",
    "        Wh: 隠れ状態`h`用の重みパラメータ（4つ分の重みをまとめる）\n",
    "        b: バイアス（4つ分のバイアスをまとめる）\n",
    "        '''\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.cache = None\n",
    "```\n",
    "\n",
    "- 初期化の引数は、重みパラメータのWx, Wh, b\n",
    "    - 重みには4つ分の重みが纏められている\n",
    "    - パラメータはメンバ変数のparamsに設定・初期化\n",
    "    - cacheは順伝播での中間結果を保持するために使用。逆伝播の計算でも使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a479b92-d9eb-41c6-8447-f4da929f2f86",
   "metadata": {},
   "source": [
    "◆順伝播の実装<br>\n",
    "- 引数は、現時刻の入力x、前時刻の隠れ状態h_prev、前時刻の記憶セルc_prev\n",
    "\n",
    "```python\n",
    "    def forward(self, x, h_prev, c_prev):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, H = h_prev.shape\n",
    "\n",
    "        A = np.dot(x, Wx) + np.dot(h_prev, Wh) + b\n",
    "\n",
    "        f = A[:, :H]\n",
    "        g = A[:, H:2*H]\n",
    "        i = A[:, 2*H:3*H]\n",
    "        o = A[:, 3*H:]\n",
    "\n",
    "        f = sigmoid(f)\n",
    "        g = np.tanh(g)\n",
    "        i = sigmoid(i)\n",
    "        o = sigmoid(o)\n",
    "\n",
    "        c_next = f * c_prev + g * i\n",
    "        h_next = o * np.tanh(c_next)\n",
    "\n",
    "        self.cache = (x, h_prev, c_prev, i, f, g, o, c_next)\n",
    "        return h_next, c_next\n",
    "```\n",
    "- まず初めにアフィン変換が行われる\n",
    " - メンバ変数のWx、Wh、bには4つ分のパラメータが格納。形状は以下の通り\n",
    " ![6_22](fig6/6_22.png)\n",
    "- バッチ数をN、入力データの次元数をD、記憶セルと隠れ状態の次元数を両者ともH\n",
    "- 計算結果のA には4 つ分のアフィン変換の結果が格納\n",
    "- そこからA[:, :H] やA[:, H:2*H] のようにスライスして取り出すことで、それ以降の演算ノードへ分配"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d382e20d-c394-4f69-b299-bb04f1a84cfc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dce10ba4-e3f8-4f0d-8b85-7f6dfa0ca23a",
   "metadata": {},
   "source": [
    "◆LSTMの逆伝播\n",
    "- 逆伝播では、4つの勾配を結合する必要あり\n",
    " ![6_23](fig6/6_23.png)\n",
    " \n",
    " \n",
    "```python\n",
    "    def backward(self, dh_next, dc_next):\n",
    "        Wx, Wh, b = self.params\n",
    "        x, h_prev, c_prev, i, f, g, o, c_next = self.cache\n",
    "\n",
    "        tanh_c_next = np.tanh(c_next)\n",
    "\n",
    "        ds = dc_next + (dh_next * o) * (1 - tanh_c_next ** 2)\n",
    "\n",
    "        dc_prev = ds * f\n",
    "\n",
    "        di = ds * g\n",
    "        df = ds * c_prev\n",
    "        do = dh_next * tanh_c_next\n",
    "        dg = ds * i\n",
    "\n",
    "        di *= i * (1 - i)\n",
    "        df *= f * (1 - f)\n",
    "        do *= o * (1 - o)\n",
    "        dg *= (1 - g ** 2)\n",
    "\n",
    "        dA = np.hstack((df, dg, di, do))\n",
    "\n",
    "        dWh = np.dot(h_prev.T, dA)\n",
    "        dWx = np.dot(x.T, dA)\n",
    "        db = dA.sum(axis=0)\n",
    "\n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "        self.grads[2][...] = db\n",
    "\n",
    "        dx = np.dot(dA, Wx.T)\n",
    "        dh_prev = np.dot(dA, Wh.T)\n",
    "\n",
    "        return dx, dh_prev, dc_prev\n",
    "```\n",
    "- 4つの勾配(df, dg, di, do)を連結してdAを作成\n",
    "    - np.hstack()　が使用可能<br>引数に与えられた配列を横方向に連結"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6b03ec-e20c-4206-a19b-7cb9758aa7b7",
   "metadata": {},
   "source": [
    "## 6.3.1 TimeLSTMの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e767f5d9-1225-422f-baae-22359ff1005d",
   "metadata": {},
   "source": [
    "- T個分の時系列データをまとめて処理するレイヤ\n",
    "![6_24](fig6/6_24.png)\n",
    "- RNNで学習を行う際には、Truncated BPTTを行う\n",
    "    - 逆伝播のつながりを適当な長さで断ち切る\n",
    "![6_25](fig6/6_25.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e078c590-4e0c-499c-923b-700c80bfbdbb",
   "metadata": {},
   "source": [
    "◆Time LSTMの実装\n",
    "- LSTM では隠れ状態のh に加えて記憶セルc も用いますが、TimeLSTM クラスの実装はTimeRNN クラスの場合とほとんど同じです。ここでも引数のstateful によって状態を維持するかどうかを指定します。\n",
    "\n",
    "```python\n",
    "class TimeLSTM:\n",
    "    def __init__(self, Wx, Wh, b, stateful=False):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "\n",
    "        self.h, self.c = None, None\n",
    "        self.dh = None\n",
    "        self.stateful = stateful\n",
    "\n",
    "    def forward(self, xs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        H = Wh.shape[0]\n",
    "\n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype='f')\n",
    "\n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeros((N, H), dtype='f')\n",
    "        if not self.stateful or self.c is None:\n",
    "            self.c = np.zeros((N, H), dtype='f')\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = LSTM(*self.params)\n",
    "            self.h, self.c = layer.forward(xs[:, t, :], self.h, self.c)\n",
    "            hs[:, t, :] = self.h\n",
    "\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        return hs\n",
    "\n",
    "    def backward(self, dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D = Wx.shape[0]\n",
    "\n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        dh, dc = 0, 0\n",
    "\n",
    "        grads = [0, 0, 0]\n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh, dc = layer.backward(dhs[:, t, :] + dh, dc)\n",
    "            dxs[:, t, :] = dx\n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "\n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "        self.dh = dh\n",
    "        return dxs\n",
    "\n",
    "    def set_state(self, h, c=None):\n",
    "        self.h, self.c = h, c\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.h, self.c = None, None\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a03f92-acfe-405b-b6aa-3d263c475baf",
   "metadata": {},
   "source": [
    "# 6.4 LSTMを使った言語モデル"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5486e05d-fc9b-47a1-ade9-bae443c10ad4",
   "metadata": {},
   "source": [
    "\n",
    "![6_26](fig6/6_26.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda254ef-e632-44f4-9d36-f39ddfbf1a0e",
   "metadata": {},
   "source": [
    "- Rnnlmというクラスで実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa56a8c3-be20-40bd-8f12-459635b7cc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.time_layers import *\n",
    "from common.base_model import BaseModel\n",
    "\n",
    "\n",
    "class Rnnlm(BaseModel):\n",
    "    def __init__(self, vocab_size=10000, wordvec_size=100, hidden_size=100):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        # 重みの初期化\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        # レイヤの生成\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layer = self.layers[1]\n",
    "\n",
    "        # すべての重みと勾配をリストにまとめる\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def predict(self, xs):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        score = self.predict(xs)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.lstm_layer.reset_state()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af536e6b-ceb8-47f4-8f49-b298482edc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ptb.test.txt ... \n",
      "Done\n",
      "| epoch 1 |  iter 1 / 1327 | time 0[s] | perplexity 9999.76\n",
      "| epoch 1 |  iter 21 / 1327 | time 4[s] | perplexity 3086.76\n",
      "| epoch 1 |  iter 41 / 1327 | time 8[s] | perplexity 1245.40\n",
      "| epoch 1 |  iter 61 / 1327 | time 11[s] | perplexity 958.52\n",
      "| epoch 1 |  iter 81 / 1327 | time 16[s] | perplexity 796.07\n",
      "| epoch 1 |  iter 101 / 1327 | time 20[s] | perplexity 672.13\n",
      "| epoch 1 |  iter 121 / 1327 | time 23[s] | perplexity 631.55\n",
      "| epoch 1 |  iter 141 / 1327 | time 27[s] | perplexity 593.06\n",
      "| epoch 1 |  iter 161 / 1327 | time 31[s] | perplexity 581.24\n",
      "| epoch 1 |  iter 181 / 1327 | time 35[s] | perplexity 593.73\n",
      "| epoch 1 |  iter 201 / 1327 | time 39[s] | perplexity 501.89\n",
      "| epoch 1 |  iter 221 / 1327 | time 44[s] | perplexity 496.71\n",
      "| epoch 1 |  iter 241 / 1327 | time 48[s] | perplexity 437.61\n",
      "| epoch 1 |  iter 261 / 1327 | time 52[s] | perplexity 456.42\n",
      "| epoch 1 |  iter 281 / 1327 | time 56[s] | perplexity 450.58\n",
      "| epoch 1 |  iter 301 / 1327 | time 60[s] | perplexity 389.20\n",
      "| epoch 1 |  iter 321 / 1327 | time 64[s] | perplexity 354.29\n",
      "| epoch 1 |  iter 341 / 1327 | time 69[s] | perplexity 401.62\n",
      "| epoch 1 |  iter 361 / 1327 | time 73[s] | perplexity 399.93\n",
      "| epoch 1 |  iter 381 / 1327 | time 77[s] | perplexity 336.82\n",
      "| epoch 1 |  iter 401 / 1327 | time 81[s] | perplexity 347.84\n",
      "| epoch 1 |  iter 421 / 1327 | time 85[s] | perplexity 340.86\n",
      "| epoch 1 |  iter 441 / 1327 | time 89[s] | perplexity 328.79\n",
      "| epoch 1 |  iter 461 / 1327 | time 94[s] | perplexity 328.87\n",
      "| epoch 1 |  iter 481 / 1327 | time 98[s] | perplexity 305.10\n",
      "| epoch 1 |  iter 501 / 1327 | time 102[s] | perplexity 316.33\n",
      "| epoch 1 |  iter 521 / 1327 | time 106[s] | perplexity 303.37\n",
      "| epoch 1 |  iter 541 / 1327 | time 110[s] | perplexity 318.85\n",
      "| epoch 1 |  iter 561 / 1327 | time 115[s] | perplexity 285.92\n",
      "| epoch 1 |  iter 581 / 1327 | time 119[s] | perplexity 260.34\n",
      "| epoch 1 |  iter 601 / 1327 | time 123[s] | perplexity 337.84\n",
      "| epoch 1 |  iter 621 / 1327 | time 127[s] | perplexity 309.29\n",
      "| epoch 1 |  iter 641 / 1327 | time 131[s] | perplexity 285.51\n",
      "| epoch 1 |  iter 661 / 1327 | time 135[s] | perplexity 270.18\n",
      "| epoch 1 |  iter 681 / 1327 | time 139[s] | perplexity 228.19\n",
      "| epoch 1 |  iter 701 / 1327 | time 143[s] | perplexity 250.73\n",
      "| epoch 1 |  iter 721 / 1327 | time 147[s] | perplexity 259.85\n",
      "| epoch 1 |  iter 741 / 1327 | time 151[s] | perplexity 226.34\n",
      "| epoch 1 |  iter 761 / 1327 | time 157[s] | perplexity 234.19\n",
      "| epoch 1 |  iter 781 / 1327 | time 161[s] | perplexity 222.54\n",
      "| epoch 1 |  iter 801 / 1327 | time 166[s] | perplexity 244.30\n",
      "| epoch 1 |  iter 821 / 1327 | time 170[s] | perplexity 225.32\n",
      "| epoch 1 |  iter 841 / 1327 | time 175[s] | perplexity 229.87\n",
      "| epoch 1 |  iter 861 / 1327 | time 179[s] | perplexity 223.03\n",
      "| epoch 1 |  iter 881 / 1327 | time 184[s] | perplexity 208.22\n",
      "| epoch 1 |  iter 901 / 1327 | time 188[s] | perplexity 254.83\n",
      "| epoch 1 |  iter 921 / 1327 | time 192[s] | perplexity 227.58\n",
      "| epoch 1 |  iter 941 / 1327 | time 197[s] | perplexity 231.32\n",
      "| epoch 1 |  iter 961 / 1327 | time 201[s] | perplexity 246.51\n",
      "| epoch 1 |  iter 981 / 1327 | time 205[s] | perplexity 230.45\n",
      "| epoch 1 |  iter 1001 / 1327 | time 209[s] | perplexity 193.63\n",
      "| epoch 1 |  iter 1021 / 1327 | time 213[s] | perplexity 227.75\n",
      "| epoch 1 |  iter 1041 / 1327 | time 217[s] | perplexity 210.69\n",
      "| epoch 1 |  iter 1061 / 1327 | time 221[s] | perplexity 199.61\n",
      "| epoch 1 |  iter 1081 / 1327 | time 226[s] | perplexity 167.85\n",
      "| epoch 1 |  iter 1101 / 1327 | time 230[s] | perplexity 194.34\n",
      "| epoch 1 |  iter 1121 / 1327 | time 234[s] | perplexity 229.81\n",
      "| epoch 1 |  iter 1141 / 1327 | time 239[s] | perplexity 208.69\n",
      "| epoch 1 |  iter 1161 / 1327 | time 243[s] | perplexity 199.70\n",
      "| epoch 1 |  iter 1181 / 1327 | time 248[s] | perplexity 191.50\n",
      "| epoch 1 |  iter 1201 / 1327 | time 252[s] | perplexity 164.35\n",
      "| epoch 1 |  iter 1221 / 1327 | time 257[s] | perplexity 159.28\n",
      "| epoch 1 |  iter 1241 / 1327 | time 261[s] | perplexity 188.74\n",
      "| epoch 1 |  iter 1261 / 1327 | time 266[s] | perplexity 172.08\n",
      "| epoch 1 |  iter 1281 / 1327 | time 270[s] | perplexity 178.61\n",
      "| epoch 1 |  iter 1301 / 1327 | time 275[s] | perplexity 224.44\n",
      "| epoch 1 |  iter 1321 / 1327 | time 279[s] | perplexity 211.18\n",
      "| epoch 2 |  iter 1 / 1327 | time 281[s] | perplexity 222.39\n",
      "| epoch 2 |  iter 21 / 1327 | time 285[s] | perplexity 206.33\n",
      "| epoch 2 |  iter 41 / 1327 | time 289[s] | perplexity 190.65\n",
      "| epoch 2 |  iter 61 / 1327 | time 294[s] | perplexity 176.65\n",
      "| epoch 2 |  iter 81 / 1327 | time 298[s] | perplexity 160.20\n",
      "| epoch 2 |  iter 101 / 1327 | time 302[s] | perplexity 152.34\n",
      "| epoch 2 |  iter 121 / 1327 | time 306[s] | perplexity 160.99\n",
      "| epoch 2 |  iter 141 / 1327 | time 311[s] | perplexity 178.88\n",
      "| epoch 2 |  iter 161 / 1327 | time 315[s] | perplexity 192.18\n",
      "| epoch 2 |  iter 181 / 1327 | time 319[s] | perplexity 204.52\n",
      "| epoch 2 |  iter 201 / 1327 | time 323[s] | perplexity 185.90\n",
      "| epoch 2 |  iter 221 / 1327 | time 328[s] | perplexity 184.14\n",
      "| epoch 2 |  iter 241 / 1327 | time 332[s] | perplexity 177.05\n",
      "| epoch 2 |  iter 261 / 1327 | time 336[s] | perplexity 185.55\n",
      "| epoch 2 |  iter 281 / 1327 | time 341[s] | perplexity 185.37\n",
      "| epoch 2 |  iter 301 / 1327 | time 345[s] | perplexity 167.94\n",
      "| epoch 2 |  iter 321 / 1327 | time 350[s] | perplexity 139.92\n",
      "| epoch 2 |  iter 341 / 1327 | time 354[s] | perplexity 173.88\n",
      "| epoch 2 |  iter 361 / 1327 | time 358[s] | perplexity 197.48\n",
      "| epoch 2 |  iter 381 / 1327 | time 362[s] | perplexity 153.71\n",
      "| epoch 2 |  iter 401 / 1327 | time 367[s] | perplexity 168.67\n",
      "| epoch 2 |  iter 421 / 1327 | time 371[s] | perplexity 154.51\n",
      "| epoch 2 |  iter 441 / 1327 | time 375[s] | perplexity 162.91\n",
      "| epoch 2 |  iter 461 / 1327 | time 380[s] | perplexity 158.69\n",
      "| epoch 2 |  iter 481 / 1327 | time 385[s] | perplexity 156.64\n",
      "| epoch 2 |  iter 501 / 1327 | time 389[s] | perplexity 170.20\n",
      "| epoch 2 |  iter 521 / 1327 | time 394[s] | perplexity 173.69\n",
      "| epoch 2 |  iter 541 / 1327 | time 398[s] | perplexity 176.27\n",
      "| epoch 2 |  iter 561 / 1327 | time 402[s] | perplexity 156.67\n",
      "| epoch 2 |  iter 581 / 1327 | time 406[s] | perplexity 139.75\n",
      "| epoch 2 |  iter 601 / 1327 | time 411[s] | perplexity 189.66\n",
      "| epoch 2 |  iter 621 / 1327 | time 415[s] | perplexity 181.62\n",
      "| epoch 2 |  iter 641 / 1327 | time 419[s] | perplexity 166.17\n",
      "| epoch 2 |  iter 661 / 1327 | time 423[s] | perplexity 155.13\n",
      "| epoch 2 |  iter 681 / 1327 | time 427[s] | perplexity 130.24\n",
      "| epoch 2 |  iter 701 / 1327 | time 432[s] | perplexity 152.43\n",
      "| epoch 2 |  iter 721 / 1327 | time 436[s] | perplexity 159.40\n",
      "| epoch 2 |  iter 741 / 1327 | time 440[s] | perplexity 133.50\n",
      "| epoch 2 |  iter 761 / 1327 | time 445[s] | perplexity 132.69\n",
      "| epoch 2 |  iter 781 / 1327 | time 449[s] | perplexity 135.24\n",
      "| epoch 2 |  iter 801 / 1327 | time 453[s] | perplexity 147.48\n",
      "| epoch 2 |  iter 821 / 1327 | time 458[s] | perplexity 143.82\n",
      "| epoch 2 |  iter 841 / 1327 | time 462[s] | perplexity 144.98\n",
      "| epoch 2 |  iter 861 / 1327 | time 466[s] | perplexity 146.97\n",
      "| epoch 2 |  iter 881 / 1327 | time 470[s] | perplexity 130.96\n",
      "| epoch 2 |  iter 901 / 1327 | time 475[s] | perplexity 165.90\n",
      "| epoch 2 |  iter 921 / 1327 | time 479[s] | perplexity 146.09\n",
      "| epoch 2 |  iter 941 / 1327 | time 483[s] | perplexity 152.68\n",
      "| epoch 2 |  iter 961 / 1327 | time 487[s] | perplexity 164.71\n",
      "| epoch 2 |  iter 981 / 1327 | time 492[s] | perplexity 154.54\n",
      "| epoch 2 |  iter 1001 / 1327 | time 496[s] | perplexity 131.55\n",
      "| epoch 2 |  iter 1021 / 1327 | time 501[s] | perplexity 157.18\n",
      "| epoch 2 |  iter 1041 / 1327 | time 505[s] | perplexity 144.51\n",
      "| epoch 2 |  iter 1061 / 1327 | time 509[s] | perplexity 128.90\n",
      "| epoch 2 |  iter 1081 / 1327 | time 514[s] | perplexity 110.19\n",
      "| epoch 2 |  iter 1101 / 1327 | time 518[s] | perplexity 122.62\n",
      "| epoch 2 |  iter 1121 / 1327 | time 522[s] | perplexity 153.81\n",
      "| epoch 2 |  iter 1141 / 1327 | time 527[s] | perplexity 142.60\n",
      "| epoch 2 |  iter 1161 / 1327 | time 531[s] | perplexity 133.60\n",
      "| epoch 2 |  iter 1181 / 1327 | time 535[s] | perplexity 135.21\n",
      "| epoch 2 |  iter 1201 / 1327 | time 540[s] | perplexity 112.65\n",
      "| epoch 2 |  iter 1221 / 1327 | time 544[s] | perplexity 109.45\n",
      "| epoch 2 |  iter 1241 / 1327 | time 549[s] | perplexity 130.24\n",
      "| epoch 2 |  iter 1261 / 1327 | time 554[s] | perplexity 124.41\n",
      "| epoch 2 |  iter 1281 / 1327 | time 559[s] | perplexity 122.87\n",
      "| epoch 2 |  iter 1301 / 1327 | time 563[s] | perplexity 158.28\n",
      "| epoch 2 |  iter 1321 / 1327 | time 568[s] | perplexity 152.87\n",
      "| epoch 3 |  iter 1 / 1327 | time 570[s] | perplexity 159.27\n",
      "| epoch 3 |  iter 21 / 1327 | time 574[s] | perplexity 144.09\n",
      "| epoch 3 |  iter 41 / 1327 | time 579[s] | perplexity 135.22\n",
      "| epoch 3 |  iter 61 / 1327 | time 583[s] | perplexity 127.70\n",
      "| epoch 3 |  iter 81 / 1327 | time 588[s] | perplexity 116.82\n",
      "| epoch 3 |  iter 101 / 1327 | time 593[s] | perplexity 104.52\n",
      "| epoch 3 |  iter 121 / 1327 | time 597[s] | perplexity 116.90\n",
      "| epoch 3 |  iter 141 / 1327 | time 602[s] | perplexity 125.55\n",
      "| epoch 3 |  iter 161 / 1327 | time 606[s] | perplexity 142.56\n",
      "| epoch 3 |  iter 181 / 1327 | time 610[s] | perplexity 152.15\n",
      "| epoch 3 |  iter 201 / 1327 | time 615[s] | perplexity 142.59\n",
      "| epoch 3 |  iter 221 / 1327 | time 619[s] | perplexity 142.02\n",
      "| epoch 3 |  iter 241 / 1327 | time 623[s] | perplexity 133.67\n",
      "| epoch 3 |  iter 261 / 1327 | time 627[s] | perplexity 139.47\n",
      "| epoch 3 |  iter 281 / 1327 | time 631[s] | perplexity 141.46\n",
      "| epoch 3 |  iter 301 / 1327 | time 635[s] | perplexity 125.38\n",
      "| epoch 3 |  iter 321 / 1327 | time 639[s] | perplexity 102.51\n",
      "| epoch 3 |  iter 341 / 1327 | time 644[s] | perplexity 124.80\n",
      "| epoch 3 |  iter 361 / 1327 | time 648[s] | perplexity 152.71\n",
      "| epoch 3 |  iter 381 / 1327 | time 652[s] | perplexity 114.67\n",
      "| epoch 3 |  iter 401 / 1327 | time 656[s] | perplexity 130.78\n",
      "| epoch 3 |  iter 421 / 1327 | time 660[s] | perplexity 113.47\n",
      "| epoch 3 |  iter 441 / 1327 | time 664[s] | perplexity 122.85\n",
      "| epoch 3 |  iter 461 / 1327 | time 668[s] | perplexity 118.97\n",
      "| epoch 3 |  iter 481 / 1327 | time 672[s] | perplexity 119.69\n",
      "| epoch 3 |  iter 501 / 1327 | time 677[s] | perplexity 128.93\n",
      "| epoch 3 |  iter 521 / 1327 | time 681[s] | perplexity 137.96\n",
      "| epoch 3 |  iter 541 / 1327 | time 685[s] | perplexity 136.46\n",
      "| epoch 3 |  iter 561 / 1327 | time 689[s] | perplexity 119.40\n",
      "| epoch 3 |  iter 581 / 1327 | time 693[s] | perplexity 105.41\n",
      "| epoch 3 |  iter 601 / 1327 | time 697[s] | perplexity 147.85\n",
      "| epoch 3 |  iter 621 / 1327 | time 702[s] | perplexity 142.01\n",
      "| epoch 3 |  iter 641 / 1327 | time 706[s] | perplexity 128.61\n",
      "| epoch 3 |  iter 661 / 1327 | time 710[s] | perplexity 120.52\n",
      "| epoch 3 |  iter 681 / 1327 | time 714[s] | perplexity 99.21\n",
      "| epoch 3 |  iter 701 / 1327 | time 718[s] | perplexity 119.77\n",
      "| epoch 3 |  iter 721 / 1327 | time 723[s] | perplexity 125.53\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-dded48492936>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# 勾配クリッピングを適用して学習\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m trainer.fit(xs, ts, max_epoch, batch_size, time_size, max_grad,\n\u001b[0m\u001b[1;32m     34\u001b[0m             eval_interval=20)\n\u001b[1;32m     35\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/00.Self-Dev/Programming/GitHub5/ゼロつく2/6_2/common/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, xs, ts, max_epoch, batch_size, time_size, max_grad, eval_interval)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0;31m# 勾配を求め、パラメータを更新\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 共有された重みを1つに集約\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/00.Self-Dev/Programming/GitHub5/ゼロつく2/6_2/code/rnnlm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, xs, ts)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/00.Self-Dev/Programming/GitHub5/ゼロつく2/6_2/common/time_layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, xs, ts)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0mls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mls\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mmask\u001b[0m  \u001b[0;31m# ignore_labelに該当するデータは損失を0にする\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/00.Self-Dev/Programming/GitHub5/ゼロつく2/6_2/common/functions.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from common.util import eval_perplexity\n",
    "from dataset import ptb\n",
    "from rnnlm import Rnnlm\n",
    "\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "batch_size = 20\n",
    "wordvec_size = 100\n",
    "hidden_size = 100  # RNNの隠れ状態ベクトルの要素数\n",
    "time_size = 35  # RNNを展開するサイズ\n",
    "lr = 20.0\n",
    "max_epoch = 4\n",
    "max_grad = 0.25\n",
    "\n",
    "# 学習データの読み込み\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_test, _, _ = ptb.load_data('test')\n",
    "vocab_size = len(word_to_id)\n",
    "xs = corpus[:-1]\n",
    "ts = corpus[1:]\n",
    "\n",
    "# モデルの生成\n",
    "model = Rnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "# 勾配クリッピングを適用して学習\n",
    "trainer.fit(xs, ts, max_epoch, batch_size, time_size, max_grad,\n",
    "            eval_interval=20)\n",
    "trainer.plot(ylim=(0, 500))\n",
    "\n",
    "# テストデータで評価\n",
    "model.reset_state()\n",
    "ppl_test = eval_perplexity(model, corpus_test)\n",
    "print('test perplexity: ', ppl_test)\n",
    "\n",
    "# パラメータの保存\n",
    "model.save_params()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf95acc-f086-4795-8cb5-3874d47e6118",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84567ff8-8a35-4769-acc7-8e970e3912ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f57848-f655-4109-ad90-e6b152f1f9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4819e49-83b5-4f42-8024-54d7393e758a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
