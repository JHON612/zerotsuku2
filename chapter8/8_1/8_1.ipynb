{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98d25d2d-7645-46ed-baf8-e520232e5762",
   "metadata": {},
   "source": [
    "# 8章 Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d061573-af3f-429e-b7a4-342299ab8a59",
   "metadata": {},
   "source": [
    "## 8.1 Attentionの仕組み"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15a82e0-5edd-49ee-9fce-af014bda5f31",
   "metadata": {},
   "source": [
    "- 注意機構(attention mechanism)\n",
    "       - seq2seqをさらに強力に。seq2seqが抱えていた問題を解決可能\n",
    "       -　必要な情報だけに「注意」を向けさせることができる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4675f059-16ec-4a85-969f-a1ccce4ca08e",
   "metadata": {},
   "source": [
    "### 8.1.1 seq2seqの問題点"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81a00c0-c336-479f-b476-9ec03e78a02d",
   "metadata": {},
   "source": [
    "- 入力分の長さにかかわらず、常に同じ長さのベクトルに変換する必要あり\n",
    "- 必要な情報がベクトルからはみ出す可能性あり\n",
    "![8_1](fig/8_1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8a8c8c-e63a-409c-a93d-a6158c8bfc5d",
   "metadata": {},
   "source": [
    "### 8.1.2 Encoderの改良"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee19a41-5eb3-4ab4-a30e-52986e191f5d",
   "metadata": {},
   "source": [
    "- Encoderの出力\n",
    "    - 入力される文書の長さに応じて長さが変わるべき\n",
    "![8_2](fig/8_2.png)\n",
    "- 各時刻(各単語)の隠れ状態ベクトルを全て利用すれば、入力された単語列と同じ数のベクトルを得ることができる。「ひとつの固定長ベクトル」という制約から解放される"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c494d00f-f7bf-41d5-9ca4-4d546258fe63",
   "metadata": {},
   "source": [
    "![8_3](fig/8_3.png)\n",
    "- Encoderが出力するhsという行列は、上図のように、各単語に対応したベクトルの集合とみなすことができる\n",
    "<br><br>\n",
    "◆Encoderの改良のまとめ\n",
    "- Encoderの隠れ状態を全て時刻分取り出し\n",
    "-　Encoderは入力文の長さに比例した情報をエンコードできるように"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d024defc-204e-49f2-81d8-f661b424d492",
   "metadata": {},
   "source": [
    "### 8.1.3 Decoderの改良①"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26b7183-d689-4c22-abad-c7a0deba38ff",
   "metadata": {},
   "source": [
    "- Encoder\n",
    "    - 各単語に対応するLSTMレイヤの隠れ状態ベクトルをhsとして出力。hsがDecoderに渡され、時系列変換が行われる\n",
    "![8_4](fig/8_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8428857d-f8be-4796-a9d4-264e6c3c46fa",
   "metadata": {},
   "source": [
    "- 前章のDecoder\n",
    "    - EncoderのLSTMレイヤにある最後の隠れ状態だけを利用\n",
    "    - 記号hsを使えば、その最後の行だけ抜き出して、それをDecoderに渡すことになる\n",
    "    ![8_5](fig/8_5.png)\n",
    "- Decoderの改良\n",
    "    - hs全てを活用できるようにする"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18545c0-246d-462f-9203-3fd3c48b77f1",
   "metadata": {},
   "source": [
    "- Attention\n",
    "    - 必要な情報にだけ注意を向けさせ、その情報から時系列変換を行う\n",
    "        - 例：「吾輩は猫である」という文を英語に翻訳するとき、「吾輩=I」「猫=cat」のように、「翻訳先の単語」と対応関係にある「翻訳元の単語」の情報を選び出すこと、そして、その情報を利用して翻訳を行う\n",
    "\n",
    "    - 全体の枠組み\n",
    "        - 下図のように「何らかの計算」を行うレイヤを追加する\n",
    "    ![8_6](fig/8_6.png)\n",
    "        - 「何らかの計算」\n",
    "            - 各時刻においてLSTMレイヤの隠れ状態とEncoderからのhsを受け取る\n",
    "            - 必要な情報だけを選び出し、Affineレイヤへと出力\n",
    "            - Encoderの最後の隠れ状態ベクトルは、Deocderの最初のLSTMレイヤに渡す<br>\n",
    "    - 単語のアライメント抽出\n",
    "         - 各時刻において、Decoderへの入力単語と対応関係にある単語のベクトルをhsから選び出す\n",
    "             - 例：上図のDecoderが「I」を出力するとき、hsの「吾輩」に対応するベクトルを選び出したい。そのような選び出す操作を「何らかの計算」で実現したい\n",
    "         - 問題点\n",
    "             -  選び出すという操作は、微分ができない\n",
    "                 - ニューラルネットワークの学習は誤差逆伝播法によって行われている為、微分可能な演算を用いなければ、誤差逆伝播方を使うことができない"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceb6b7f-da0e-4427-8e9d-8879d00ff3e3",
   "metadata": {},
   "source": [
    "- 「選ぶ」という操作を微分可能な演算に置き換える方法\n",
    "    - 「ひとつを選ぶ」のではなく、「すべてを選ぶ」ようにする\n",
    "    - この時、各単語の重要度(貢献度)を表す「重み」を別途計算するようにする\n",
    "    ![8_7](fig/8_7.png)\n",
    "    - 各単語の重要度を表す「重み」(記号aで表す)を利用\n",
    "        - aは0.0~1.0のスカラで、総和は1になる\n",
    "        - 各単語の重要度を表す重みaと各単語のベクトルhsから、重み付き和を求めることで目的のベクトルを得る\n",
    " ![8_8](fig/8_8.png)\n",
    "- コンテキストベクトル(c)\n",
    "    -　現時刻の変換(翻訳)を行うために必要な情報が含まれている\n",
    "- ここまでの話をコードベースで見たのが下図\n",
    "    - Encoderが出力するhsと各単語の重みaを適当に作成しその重み付き和を求める\n",
    "    - 時系列の長さをT=5、隠れ層ベクトルの要素数をH=4として重み付き和を求める過程を示す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ce13cdc-b36b-4433-81a0-1ee2950f1b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 4)\n",
      "(5, 4)\n",
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "T, H = 5, 4\n",
    "hs = np.random.randn(T, H)\n",
    "a = np.array([0.8, 0.1, 0.03, 0.05, 0.02])\n",
    "ar = a.reshape(5, 1).repeat(4, axis=1)\n",
    "print(ar.shape)\n",
    "# (5, 4)\n",
    "t = hs * ar\n",
    "\n",
    "print(t.shape)\n",
    "c = np.sum(t, axis=0)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d514f90-6353-43d5-829d-43f44ec94d78",
   "metadata": {},
   "source": [
    "![8_9](fig/8_9.png)\n",
    "<br><br>\n",
    "- NumPyのブロードキャストも利用可\n",
    "![8_10](fig/8_10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2678c27c-5eb7-40d5-8e3a-ad5e4064d5a9",
   "metadata": {},
   "source": [
    "- バッチ処理版の重み付き和の実装は以下の通り"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67db22c2-0c9d-4a47-8bc6-f5e6b64f09d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5, 4)\n",
      "(10, 4)\n"
     ]
    }
   ],
   "source": [
    "N, T, H = 10, 5, 4\n",
    "hs = np.random.randn(N, T, H)\n",
    "a = np.random.randn(N, T)\n",
    "ar = a.reshape(N, T, 1).repeat(H, axis=2)\n",
    "# ar = a.reshape(N, T, 1) # ブロードキャストを使う場合\n",
    "t = hs * ar\n",
    "print(t.shape)\n",
    "# (10, 5, 4)\n",
    "c = np.sum(t, axis=1)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c5f74e-ad5e-4264-a22a-f3962e08fe08",
   "metadata": {},
   "source": [
    "- 重み付き和の計算を「計算グラフ」で表したもの\n",
    "\n",
    "![8_11](fig/8_11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba64ae6d-c12e-481a-897e-0341cd6e5bec",
   "metadata": {},
   "source": [
    "- 逆伝播の実装\n",
    "    - Repeatの逆伝播はSum\n",
    "    - Sumの逆伝播はRepeat\n",
    "\n",
    "```python\n",
    "class WeightSum:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, hs, a):\n",
    "        N, T, H = hs.shape\n",
    "\n",
    "        ar = a.reshape(N, T, 1)#.repeat(T, axis=1)\n",
    "        t = hs * ar\n",
    "        c = np.sum(t, axis=1)\n",
    "\n",
    "        self.cache = (hs, ar)\n",
    "        return c\n",
    "\n",
    "    def backward(self, dc):\n",
    "        hs, ar = self.cache\n",
    "        N, T, H = hs.shape\n",
    "        dt = dc.reshape(N, 1, H).repeat(T, axis=1)\n",
    "        dar = dt * hs\n",
    "        dhs = dt * ar\n",
    "        da = np.sum(dar, axis=2)\n",
    "\n",
    "        return dhs, da\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122d66d7-0e8d-42dd-8e36-67d5d9adb998",
   "metadata": {},
   "source": [
    "- 上記がコンテキストベクトルを求めるWeight Sumレイヤの実装\n",
    "- 学習するパラメータは持たないので、self.params=[]とする。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79bf141-2a83-4f36-9b9d-e5505cc24057",
   "metadata": {},
   "source": [
    "### 8.1.4 Decoderの改良②"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf6e03a-5051-4677-b03e-371fe3e44c85",
   "metadata": {},
   "source": [
    "- 各単語の重要度を示す重みaの求める方法をみていく\n",
    "- 下図はDecoderの最初のステップ(時刻)でLSTMレイヤが隠れ状態ベクトルを出力するまでの処理を示したもの\n",
    "![8_12](fig/8_12.png)\n",
    "- 上図では、DecoderのLSTMレイヤの隠れ状態ベクトルをhで表している\n",
    "-　hが、hsの各単語ベクトルとどれだけ似ているかを数値で表すことを目指す\n",
    "    - ベクトルの内積を利用\n",
    "        - $ a・b = a_1b_1 + a_2b_2 + ・・・ + a_nb_n$\n",
    "        - 2つのベクトルがどれだけ同じ方向を向いているかという「類似度」をみる\n",
    "        - 内積によってベクトル間の類似度を算出するまでの処理は下図\n",
    "        ![8_13](fig/8_13.png)\n",
    "        - 類似度の算出結果をsで示す\n",
    "        - sを正規化するために、Softmax関数を適用する\n",
    "        ![8_14](fig/8_14.png)\n",
    "        - Softmax関数を用いることで、その出力であるaの各要素は0.0~0.1で、総和は1となる\n",
    "        - これまでの処理をコードベースでみたのが下記"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec65442c-4ed5-4e74-8da1-36746aa4c830",
   "metadata": {},
   "source": [
    "```python\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.layers import Softmax\n",
    "import numpy as np\n",
    "\n",
    "N, T, H = 10, 5, 4\n",
    "hs = np.random.randn(N, T, H)\n",
    "h = np.random.randn(N, H)\n",
    "hr = h.reshape(N, 1, H).repeat(T, axis=1)\n",
    "# hr = h.reshape(N, 1, H) # ブロードキャストの場合\n",
    "\n",
    "t = hs * hr\n",
    "print(t.shape)\n",
    "\n",
    "# (10, 5, 4)\n",
    "s = np.sum(t, axis=2)\n",
    "print(s.shape)\n",
    "# (10, 5)\n",
    "\n",
    "softmax = Softmax()\n",
    "a = softmax.forward(s)\n",
    "\n",
    "print(a.shape)\n",
    "# (10, 5)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14eba8ba-88bd-47de-8d5f-da850e64c347",
   "metadata": {},
   "source": [
    "- 計算グラフは下記\n",
    "\n",
    "![8_15](fig/8_15.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cd08b5-0478-4748-8927-b5a33116d010",
   "metadata": {},
   "source": [
    "- 上記計算グラフをAttentionWeightクラスとして実装したのが下図"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebf4c70-3a49-4012-ba9a-bf88c47dc121",
   "metadata": {},
   "source": [
    "```python\n",
    "class AttentionWeight:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.softmax = Softmax()\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, hs, h):\n",
    "        N, T, H = hs.shape\n",
    "\n",
    "        hr = h.reshape(N, 1, H)#.repeat(T, axis=1)\n",
    "        t = hs * hr\n",
    "        s = np.sum(t, axis=2)\n",
    "        a = self.softmax.forward(s)\n",
    "\n",
    "        self.cache = (hs, hr)\n",
    "        return a\n",
    "\n",
    "    def backward(self, da):\n",
    "        hs, hr = self.cache\n",
    "        N, T, H = hs.shape\n",
    "\n",
    "        ds = self.softmax.backward(da)\n",
    "        dt = ds.reshape(N, T, 1).repeat(H, axis=2)\n",
    "        dhs = dt * hr\n",
    "        dhr = dt * hs\n",
    "        dh = np.sum(dhr, axis=1)\n",
    "\n",
    "        return dhs, dh\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4708fad-f351-4191-bfa7-d95148208bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bebe57d5-a275-4503-89d9-6ee7d8396c01",
   "metadata": {},
   "source": [
    "### 8.1.5 Decoderの改良③"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c736f2f8-eeb7-477d-a377-409d07764e8c",
   "metadata": {},
   "source": [
    "- ここまで、Decoderの改善策を2つのレイヤに分けて説明\n",
    "    - 8.1.3ではWeight Sumレイヤ\n",
    "    - 8.1.4ではAttention Weghtレイヤ\n",
    "- 2つのレイヤを組み合わせる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef921fbe-16d5-4b1b-951e-e7c92a3c81ad",
   "metadata": {},
   "source": [
    "\n",
    "![8_16](fig/8_16.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88472e9b-91ea-48df-93f6-0617c94be65c",
   "metadata": {},
   "source": [
    "- Attentionレイヤ\n",
    "    - Attention Weightレイヤ・・・注意を払い、各単語の重みaを求める\n",
    "    - Weight Sumレイヤ・・・aとhsの重み付き和を求め、それをコンテキストベクトルcとして出力\n",
    "    - 計算グラフは下図"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cbf9d8-80d7-4484-996d-b8ac95b627a3",
   "metadata": {},
   "source": [
    "![8_17](fig/8_17.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9d390e-5e8c-47b2-b2ba-70557d5456e3",
   "metadata": {},
   "source": [
    "- 以上がAttentionレイヤの技術の革新\n",
    "    - Encoderが渡す情報hsの重要な要素に注意を払い、それを元にコンテキストベクトルを算出し、それを上層へと伝播する\n",
    "    - 実装は下図"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c6876f-07bd-4cf6-926b-432207603824",
   "metadata": {},
   "source": [
    "```python\n",
    "class Attention:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.attention_weight_layer = AttentionWeight()\n",
    "        self.weight_sum_layer = WeightSum()\n",
    "        self.attention_weight = None\n",
    "\n",
    "    def forward(self, hs, h):\n",
    "        a = self.attention_weight_layer.forward(hs, h)\n",
    "        out = self.weight_sum_layer.forward(hs, a)\n",
    "        self.attention_weight = a\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dhs0, da = self.weight_sum_layer.backward(dout)\n",
    "        dhs1, dh = self.attention_weight_layer.backward(da)\n",
    "        dhs = dhs0 + dhs1\n",
    "        return dhs, dh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df067549-0206-4cb4-a8a2-81f09494c58b",
   "metadata": {},
   "source": [
    "- ここでは2つのレイヤ(Weight SumレイヤとAttention Weightレイヤ)による順伝播と逆伝播を行うのみ\n",
    "- 各単語の重みを後ほど参照できるようにするため、attention_weightというメンバ変数を設定\n",
    "\n",
    "- Attentionレイヤを、LSTMレイヤとAffineレイヤの間に挿入したのが下図"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c33c12-baf4-4df1-92d2-d54f8b3dca34",
   "metadata": {},
   "source": [
    "![8_18](fig/8_18.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69421fc-80c8-4475-bd34-147efba1a9a9",
   "metadata": {},
   "source": [
    "- 各時刻のAttentionレイヤには、Encoderの出力であるhsが入力される\n",
    "- LSTMレイヤの隠れ状態ベクトルをAffineレイヤへ入力\n",
    "- 前章のDecoderに対して、Attentionの情報を追加することになる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0f8312-a276-42d2-bc9e-060a5a064b6c",
   "metadata": {},
   "source": [
    "![8_19](fig/8_19.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf87ceb4-7d73-403b-b231-8df268207e47",
   "metadata": {},
   "source": [
    "- 前章のDecoderに対して、Attentionレイヤによるコンテキストベクトルの情報を追加\n",
    "- Affineレイヤへは、これまで通りLSTMレイヤの隠れ状態ベクトルを与え、それに追加して、Attentionレイヤのコンテキストベクトルも入力することに"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2765a91c-81d8-4c10-8504-82920f9e746d",
   "metadata": {},
   "source": [
    "- 最後に、時系列方向に広がった複数のAttentionレイヤをTime Attentionレイヤとしてまとめて実装することにします"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a82248-99b5-47ba-a498-d5ec6aba6fbe",
   "metadata": {},
   "source": [
    "\n",
    "![8_20](fig/8_20.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e7f7b5-698e-4aa8-9cc0-1651b2048e3b",
   "metadata": {},
   "source": [
    "- Time Attentionレイヤは、複数のAttentionレイヤをまとめる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4475e400-db13-4811-92c8-47d85637201b",
   "metadata": {},
   "source": [
    "```python\n",
    "class TimeAttention:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.layers = None\n",
    "        self.attention_weights = None\n",
    "\n",
    "    def forward(self, hs_enc, hs_dec):\n",
    "        N, T, H = hs_dec.shape\n",
    "        out = np.empty_like(hs_dec)\n",
    "        self.layers = []\n",
    "        self.attention_weights = []\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = Attention()\n",
    "            out[:, t, :] = layer.forward(hs_enc, hs_dec[:,t,:])\n",
    "            self.layers.append(layer)\n",
    "            self.attention_weights.append(layer.attention_weight)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        N, T, H = dout.shape\n",
    "        dhs_enc = 0\n",
    "        dhs_dec = np.empty_like(dout)\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = self.layers[t]\n",
    "            dhs, dh = layer.backward(dout[:, t, :])\n",
    "            dhs_enc += dhs\n",
    "            dhs_dec[:,t,:] = dh\n",
    "\n",
    "        return dhs_enc, dhs_dec\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f78ab49-285f-4843-8f6b-5da158f8c5c4",
   "metadata": {},
   "source": [
    "- ここでは、必要な数だけAttentionレイヤを作成し、それぞれが順伝播と逆伝播を行う。\n",
    "- また、各Attentionレイヤの各単語への重みをattention_weightsとしてリストで持つようにする\n",
    "- 次節以降では、このAttentionを使って、seq2seqの実装を行なっていく"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
